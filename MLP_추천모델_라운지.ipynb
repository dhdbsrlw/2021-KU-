{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "라운지_모델_최종.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVtFux4F1IZ4",
        "outputId": "0527abb0-c2a9-43b3-cd87-51847e16af28"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsO1qzvkU_Oq",
        "outputId": "2ae82990-c411-458b-9470-d658029d629e"
      },
      "source": [
        "# loss 그래프를 그리기 위한 도구 설치\n",
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.4-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 26.6 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 30.4 MB/s eta 0:00:01\r\u001b[K     |████████                        | 30 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 40 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 51 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 71 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 81 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 92 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 102 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 112 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 122 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 124 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Kro1DwRO9n4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import copy\n",
        "from itertools import chain\n",
        "from keras.datasets import mnist\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tensorboardX import SummaryWriter\n",
        "writer = SummaryWriter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Binut7tJ67fk",
        "outputId": "bdc8b9a0-5753-4d1a-c92c-800a748d8db6"
      },
      "source": [
        "# 불러와야 하는 파일\n",
        "# 1. 라운지_트루라벨_3.csv\n",
        "# 2. 건물 인코딩.csv\n",
        "# 3. 라운지 사용자 5000 최종.csv\n",
        "# 4. 라운지 데이터 최종.csv\n",
        "# 5. 건물별 이동시간 최종.csv\n",
        "\n",
        "#\t사용자\t위치\t시간\t사용자 수\t책상 높이\t콘센트 필요도\t컴퓨터 필요도\t정수기/화장실 유무\n",
        "raw_data_users = pd.read_csv('/content/drive/My Drive/데이터톤/보고서 작성 시 사용할 최종 파일/데이터 및 전처리/라운지+혼잡도/라운지 사용자 5000 최종.csv',encoding='euc-kr')\n",
        "\n",
        "#\t라운지\t위치(층)\t책상 높이\t테이블 수\t의자 수\t냉난방장치\t콘센트 수\t창문\t컴퓨터\t정수기\t화장실\t혼잡도  건물\n",
        "raw_data_lounge = pd.read_csv('/content/drive/My Drive/데이터톤/보고서 작성 시 사용할 최종 파일/데이터 및 전처리/라운지+혼잡도/라운지 데이터 최종.csv',encoding='euc-kr')\n",
        "raw_data_lounge['건물'] = raw_data_lounge['건물'].replace({' ':''}, regex=True)\n",
        "\n",
        "#건물-건물\n",
        "distance_buildings = pd.read_csv('/content/drive/My Drive/데이터톤/보고서 작성 시 사용할 최종 파일/데이터 및 전처리/건물별 이동시간 최종.csv',encoding='utf-8')\n",
        "\n",
        "lounge_truedata = pd.read_csv('/content/drive/My Drive/데이터톤/보고서 작성 시 사용할 최종 파일/데이터 및 전처리/라운지+혼잡도/라운지_트루라벨_3.csv',encoding='euc-kr')\n",
        "encoding_df = pd.read_csv('/content/drive/My Drive/데이터톤/보고서 작성 시 사용할 최종 파일/데이터 및 전처리/건물 인코딩.csv')\n",
        "\n",
        "lounge_truedata.score = lounge_truedata.score.apply(eval)\n",
        "lounge_truedata.score = lounge_truedata.score.apply(np.array)\n",
        "print(len(lounge_truedata.score[1]))\n",
        "lounge_truedata = lounge_truedata.to_numpy()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "239\n",
            "     lounge_index        건물         라운지  위치(층)  책상 높이  ...  창문  컴퓨터  정수기  화장실  혼잡도\n",
            "0               0   4.18기념관   4.18기념관-1     -2      1  ...   1    6    0    1  NaN\n",
            "1               1   4.18기념관   4.18기념관-2     -1      1  ...   1    0    1    1  NaN\n",
            "2               2   4.18기념관   4.18기념관-3      0      1  ...   0    0    0    0  NaN\n",
            "3               3   4.18기념관   4.18기념관-4     -2      1  ...   0    0    0    1  NaN\n",
            "4               4     CJ법학관     CJ법학관-1      0      1  ...   1    0    1    1  NaN\n",
            "..            ...       ...         ...    ...    ...  ...  ..  ...  ...  ...  ...\n",
            "234           234  현대자동차경영관  현대자동차경영관-6     -1      1  ...   1    4    1    0  NaN\n",
            "235           235  현대자동차경영관  현대자동차경영관-7      5      1  ...   1    0    1    1  NaN\n",
            "236           236     환경실험관     환경실험관-1      2      1  ...   1    0    0    1  NaN\n",
            "237           237     환경실험관     환경실험관-2      3      1  ...   1    0    0    1  NaN\n",
            "238           238     환경실험관     환경실험관-3      3      1  ...   0    7    0    1  NaN\n",
            "\n",
            "[239 rows x 14 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSKr7CvsrS9e",
        "outputId": "e42f4b06-34e9-4047-e493-445aa1a46499"
      },
      "source": [
        "#encoding raw dataframes\n",
        "\n",
        "def df_completion(user):\n",
        "    user_building = user['위치']\n",
        "    distance = distance_buildings[['building', user_building]].copy()\n",
        "    distance.rename(columns = {user_building: '거리'}, inplace = True)\n",
        "\n",
        "    #라운지\t위치(층)\t책상 높이\t테이블 수\t의자 수\t냉난방장치\t콘센트 수\t창문\t컴퓨터\t정수기\t화장실\t혼잡도\t건물\t***거리\n",
        "    lounge_with_distance = pd.merge(raw_data_lounge, distance, left_on= '건물', right_on='building', how ='left' ).drop(columns=['building'])\n",
        "\n",
        "    \n",
        "    day = str(pd.to_datetime(user['시간'].split('T')[0]).dayofweek)\n",
        "    user_c = pd.read_csv('/content/drive/My Drive/데이터톤/보고서 작성 시 사용할 최종 파일/데이터 및 전처리/라운지+혼잡도/혼잡도_월.csv')\n",
        "\n",
        "    #find day\n",
        "    if day==1:\n",
        "        user_c =  pd.read_csv('/content/drive/My Drive/데이터톤/보고서 작성 시 사용할 최종 파일/데이터 및 전처리/라운지+혼잡도/혼잡도_화.csv')\n",
        "    elif day==2:\n",
        "        user_c = pd.read_csv('/content/drive/My Drive/데이터톤/보고서 작성 시 사용할 최종 파일/데이터 및 전처리/라운지+혼잡도/혼잡도_수.csv')\n",
        "    elif day==3:\n",
        "        user_c = pd.read_csv('/content/drive/My Drive/데이터톤/보고서 작성 시 사용할 최종 파일/데이터 및 전처리/라운지+혼잡도/혼잡도_목.csv')\n",
        "    elif day==4:\n",
        "        user_c = pd.read_csv('/content/drive/My Drive/데이터톤/보고서 작성 시 사용할 최종 파일/데이터 및 전처리/라운지+혼잡도/혼잡도_금.csv')\n",
        "\n",
        "    range = pd.date_range(\"09:00\", \"23:30\", freq=\"30min\").strftime('%H:%M:%S')\n",
        "    dt = pd.to_datetime(user['시간']).round('30min')\n",
        "    user_c_r = range.get_loc(str(dt).split(' ')[1].split('+')[0])\n",
        "\n",
        "    #라운지\t위치(층)\t책상 높이\t테이블 수\t의자 수\t냉난방장치\t콘센트 수\t창문\t컴퓨터\t정수기\t화장실\t***혼잡도\t건물    거리\n",
        "    lounge_with_congestion = lounge_with_distance\n",
        "    lounge_with_congestion['혼잡도']=lounge_with_congestion.apply(lambda row: user_c[row.건물][user_c_r], axis=1)\n",
        "\n",
        "    final_lounge = pd.merge(lounge_with_congestion, encoding_df, left_on= '건물', right_on='building', how ='left')\n",
        "    final_lounge = final_lounge.drop(['건물','building','라운지','위치(층)'], axis =1)\n",
        "    final_lounge = final_lounge.rename({'encoding':'건물', 'lounge_index':'라운지'},axis=1)\n",
        "\n",
        "    final_user = pd.merge(raw_data_users, encoding_df, left_on= '위치', right_on='building', how ='left')\n",
        "    final_user = final_user.drop(['위치','building','시간'], axis =1)\n",
        "    final_user = final_user.rename({'encoding':'건물'},axis=1)\n",
        "\n",
        "    return final_lounge, final_user\n",
        "\n",
        "lounge_df, user_df = df_completion(raw_data_users.iloc[100])\n",
        "print(lounge_df)\n",
        "print(user_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     라운지  책상 높이  테이블 수  의자 수  냉난방장치  콘센트 수  ...  컴퓨터  정수기  화장실       혼잡도     거리  건물\n",
            "0      0      1      2     6      0      4  ...    6    0    1  0.313718   99.6  19\n",
            "1      1      1      1     2      0      4  ...    0    1    1  0.313718   99.6  19\n",
            "2      2      1      6    30      1      4  ...    0    0    0  0.313718   99.6  19\n",
            "3      3      1      6    24      0      7  ...    0    0    1  0.313718   99.6  19\n",
            "4      4      1      7    14      1      3  ...    0    1    1  0.351093  169.0  28\n",
            "..   ...    ...    ...   ...    ...    ...  ...  ...  ...  ...       ...    ...  ..\n",
            "234  234      1     15    60      0      5  ...    4    1    0  0.000000  243.7  32\n",
            "235  235      1     15    15      1      2  ...    0    1    1  0.000000  243.7  32\n",
            "236  236      1     13    65      0      2  ...    0    0    1  0.481289  123.7  69\n",
            "237  237      1     15    15      0      1  ...    0    0    1  0.481289  123.7  69\n",
            "238  238      1     13    52      0      1  ...    7    0    1  0.481289  123.7  69\n",
            "\n",
            "[239 rows x 13 columns]\n",
            "       사용자  사용자 수  책상 높이  콘센트 필요도  컴퓨터 필요도  정수기/화장실 유무  건물\n",
            "0        1      3      1        2        1           1  96\n",
            "1        2      6      1        4        1           0  92\n",
            "2        3      4      1        5        1           0  34\n",
            "3        4      1      1        1        2           1  29\n",
            "4        5      3      1        4        5           0  13\n",
            "...    ...    ...    ...      ...      ...         ...  ..\n",
            "4995  4996      4      1        4        1           0  50\n",
            "4996  4997      3      1        5        1           0  62\n",
            "4997  4998      4      1        4        2           1  89\n",
            "4998  4999      2      0        1        1           0  55\n",
            "4999  5000      3      1        4        2           1  79\n",
            "\n",
            "[5000 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPtZTxPYzIOJ"
      },
      "source": [
        "# 모델에 넣기 위해 데이터 형식 dataframe --> numpy로 변화\n",
        "np.random.seed(2)\n",
        "ind = np.random.rand(len(user_df)) < 0.8\n",
        "train_df = user_df[ind]\n",
        "train = train_df.to_numpy()\n",
        "val_df = user_df[~ind]\n",
        "val = val_df.to_numpy()\n",
        "lounge = lounge_df.to_numpy()\n",
        "\n",
        "len_train = len(train)\n",
        "len_lounge = len(lounge)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIeeL-AqnuSg"
      },
      "source": [
        "# model \n",
        "\n",
        "# batch_size = total classroom\n",
        "\n",
        "class NNCollabFiltering(nn.Module):\n",
        "    def __init__(self, emb_size=10, n_hidden=100):\n",
        "        super(NNCollabFiltering, self).__init__()\n",
        "        self.emb_size = emb_size\n",
        "        self.user_emb = nn.Embedding(100, emb_size)\n",
        "        self.item_emb = nn.Embedding(600, emb_size)\n",
        "        self.lin1 = nn.Linear(1800, n_hidden)\n",
        "        self.lin2 = nn.Linear(n_hidden, 1)\n",
        "        self.drop1 = nn.Dropout(0.1)\n",
        "        \n",
        "    def forward(self, u, v):\n",
        "        U = self.user_emb(u)\n",
        "        U = torch.reshape(U, (239, 6 * self.emb_size))\n",
        "        V = self.item_emb(v)\n",
        "        V = torch.reshape(V, (239, 12 * self.emb_size))\n",
        "        x = F.relu(torch.cat([U, V], dim=1))\n",
        "        x = self.drop1(x)\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = self.lin2(x)\n",
        "        x = torch.flatten(x)\n",
        "        return x\n",
        "model = NNCollabFiltering(emb_size=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX1wyDs86e0v"
      },
      "source": [
        "# validation model\n",
        "def validation_loss(model, unsqueeze=False):\n",
        "    model.eval()\n",
        "    total_loss =  0.0\n",
        "\n",
        "    for user in range(5000-len_train):\n",
        "      user_scale = np.array(val[user,1:].tolist()*239).reshape((239,6))\n",
        "      users = torch.LongTensor(user_scale)\n",
        "      val_index = user+len_train\n",
        "      lounge_df, trash_df = df_completion(raw_data_users.iloc[val_index])\n",
        "      l = lounge_df.to_numpy()\n",
        "      lounges = torch.LongTensor(l[:,1:])\n",
        "      TL = torch.FloatTensor(lounge_truedata[val[user,0]-1,1])\n",
        "      y_hat = model(users, lounges)\n",
        "      loss = F.mse_loss(y_hat, TL)\n",
        "      total_loss += loss.item()\n",
        "    \n",
        "    avg_loss = total_loss / (5000-len_train)\n",
        "    print(\"validation loss {:.7f}\".format(avg_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHiz6l6mBusZ"
      },
      "source": [
        "# train model\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay= 1e-6)\n",
        "def train_mf(model, epochs=10, unsqueeze=False):\n",
        "    model.train()\n",
        "    for i in range(epochs):\n",
        "      running_loss = 0.0 \n",
        "\n",
        "      for user in range(len_train):\n",
        "        optimizer.zero_grad()\n",
        "        user_scale = np.array(train[user,1:].tolist()*239).reshape((239,6))\n",
        "        users = torch.LongTensor(user_scale)\n",
        "        lounge_df, trash_df = df_completion(raw_data_users.iloc[user])\n",
        "        l = lounge_df.to_numpy()\n",
        "        lounges = torch.LongTensor(l[:,1:])\n",
        "        TL = torch.FloatTensor(lounge_truedata[train[user,0]-1,1].reshape((239)))\n",
        "        y_hat = model(users, lounges)\n",
        "        loss = F.mse_loss(y_hat, TL)\n",
        "        writer.add_scalar(\"Loss/train\", loss, i*len_train+user+1)\n",
        "        loss.backward(retain_graph=True)\n",
        "        running_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        if (user) % 500 == 499 :\n",
        "          print('epochs:', i, ', iter: ', user+1)\n",
        "          print(running_loss/500)  \n",
        "          running_loss = 0.0\n",
        "    writer.flush()\n",
        "    validation_loss(model, unsqueeze)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_98itVIB_3CA",
        "outputId": "4c8a1d46-9ae2-4b29-d4b1-0246d3b9c280"
      },
      "source": [
        "# train start & train 중간 loss 출력\n",
        "writer.flush()\n",
        "train_mf(model, epochs=7, unsqueeze=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epochs: 0 , iter:  500\n",
            "1.748241360425949\n",
            "epochs: 0 , iter:  1000\n",
            "1.2212200728058815\n",
            "epochs: 0 , iter:  1500\n",
            "1.1896479316949844\n",
            "epochs: 0 , iter:  2000\n",
            "1.101890043914318\n",
            "epochs: 0 , iter:  2500\n",
            "1.071766622722149\n",
            "epochs: 0 , iter:  3000\n",
            "1.0190252646803857\n",
            "epochs: 0 , iter:  3500\n",
            "0.974522844016552\n",
            "epochs: 0 , iter:  4000\n",
            "0.9974992358088494\n",
            "epochs: 1 , iter:  500\n",
            "0.9678609531521797\n",
            "epochs: 1 , iter:  1000\n",
            "0.9308658693432807\n",
            "epochs: 1 , iter:  1500\n",
            "0.9372460834383964\n",
            "epochs: 1 , iter:  2000\n",
            "0.7941069692969323\n",
            "epochs: 1 , iter:  2500\n",
            "0.6606093652248383\n",
            "epochs: 1 , iter:  3000\n",
            "0.5662894072532654\n",
            "epochs: 1 , iter:  3500\n",
            "0.5136809864342212\n",
            "epochs: 1 , iter:  4000\n",
            "0.46219301226735116\n",
            "epochs: 2 , iter:  500\n",
            "0.4255387874543667\n",
            "epochs: 2 , iter:  1000\n",
            "0.38810072737932205\n",
            "epochs: 2 , iter:  1500\n",
            "0.3355223126411438\n",
            "epochs: 2 , iter:  2000\n",
            "0.2900530182868242\n",
            "epochs: 2 , iter:  2500\n",
            "0.31369752828776837\n",
            "epochs: 2 , iter:  3000\n",
            "0.27177005530893805\n",
            "epochs: 2 , iter:  3500\n",
            "0.2458251972347498\n",
            "epochs: 2 , iter:  4000\n",
            "0.23181429855525493\n",
            "epochs: 3 , iter:  500\n",
            "0.21992664724588395\n",
            "epochs: 3 , iter:  1000\n",
            "0.20963746286928653\n",
            "epochs: 3 , iter:  1500\n",
            "0.2427192218899727\n",
            "epochs: 3 , iter:  2000\n",
            "0.19334621831774712\n",
            "epochs: 3 , iter:  2500\n",
            "0.1874477977603674\n",
            "epochs: 3 , iter:  3000\n",
            "0.16986787159740924\n",
            "epochs: 3 , iter:  3500\n",
            "0.16936329935491085\n",
            "epochs: 3 , iter:  4000\n",
            "0.17258287316560744\n",
            "epochs: 4 , iter:  500\n",
            "0.15285810698568822\n",
            "epochs: 4 , iter:  1000\n",
            "0.14987555748224257\n",
            "epochs: 4 , iter:  1500\n",
            "0.16786090151965619\n",
            "epochs: 4 , iter:  2000\n",
            "0.13352129361778498\n",
            "epochs: 4 , iter:  2500\n",
            "0.12626927875727414\n",
            "epochs: 4 , iter:  3000\n",
            "0.12641273118555546\n",
            "epochs: 4 , iter:  3500\n",
            "0.1468280700147152\n",
            "epochs: 4 , iter:  4000\n",
            "0.12976288221031426\n",
            "epochs: 5 , iter:  500\n",
            "0.11544593132287263\n",
            "epochs: 5 , iter:  1000\n",
            "0.11627558042109012\n",
            "epochs: 5 , iter:  1500\n",
            "0.13487334543466567\n",
            "epochs: 5 , iter:  2000\n",
            "0.10850398067384959\n",
            "epochs: 5 , iter:  2500\n",
            "0.10750917624682188\n",
            "epochs: 5 , iter:  3000\n",
            "0.10592379676550627\n",
            "epochs: 5 , iter:  3500\n",
            "0.12208889746665955\n",
            "epochs: 5 , iter:  4000\n",
            "0.09790335871279239\n",
            "epochs: 6 , iter:  500\n",
            "0.10198621583729982\n",
            "epochs: 6 , iter:  1000\n",
            "0.10040542459487915\n",
            "epochs: 6 , iter:  1500\n",
            "0.11850668635219336\n",
            "epochs: 6 , iter:  2000\n",
            "0.0946051354855299\n",
            "epochs: 6 , iter:  2500\n",
            "0.09342232093214989\n",
            "epochs: 6 , iter:  3000\n",
            "0.08776397372037173\n",
            "epochs: 6 , iter:  3500\n",
            "0.10574049914628267\n",
            "epochs: 6 , iter:  4000\n",
            "0.09061736711114644\n",
            "validation loss 0.0740702\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9E-OAPFgRTD"
      },
      "source": [
        "# 모델 저장\n",
        "PATH = '/content/drive/My Drive/데이터톤/보고서 작성 시 사용할 최종 파일/데이터 및 전처리/라운지+혼잡도/model_3/'\n",
        "\n",
        "torch.save(model, PATH + 'model.pt')  # 전체 모델 저장\n",
        "torch.save(model.state_dict(), PATH + 'model_state_dict.pt')  # 모델 객체의 state_dict 저장\n",
        "torch.save({\n",
        "'model': model.state_dict(),\n",
        "'optimizer': optimizer.state_dict()\n",
        "}, PATH + 'all.tar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwEbP5w-nId1"
      },
      "source": [
        "# 모델 불러오기\n",
        "model = torch.load(PATH + 'model.pt')  \n",
        "model.load_state_dict(torch.load(PATH + 'model_state_dict.pt'))  \n",
        "checkpoint = torch.load(PATH + 'all.tar')  \n",
        "model.load_state_dict(checkpoint['model'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgZmj9EUnL81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bb3fb6dc-9e8b-455f-f392-e3339297647f"
      },
      "source": [
        "# 라운지 9개 추출\n",
        "\n",
        "new_user = [3, 1, 4, 5, 0,  13]\n",
        "\n",
        "def top9(model, user, unsqueeze=False):\n",
        "  with torch.no_grad():\n",
        "    user_scale = np.array(user*239).reshape((239,6))\n",
        "    one_user = torch.LongTensor(user_scale)\n",
        "    l = lounge_df.to_numpy()\n",
        "    lounges = torch.LongTensor(l[:,1:])\n",
        "    out = model(one_user, lounges).numpy()\n",
        "    print(out)\n",
        "    sort_out = np.argsort(out)\n",
        "    print(sort_out)\n",
        "    final = np.argsort(-sort_out)\n",
        "    print(final)\n",
        "    top9 = final[:9]\n",
        "    print(top9)\n",
        "    return top9\n",
        "\n",
        "top9_index = top9(model, new_user, unsqueeze=True)\n",
        "\n",
        "\n",
        "top9_df = pd.DataFrame(top9_index, columns =['lounge_index'])\n",
        "print(top9_df)\n",
        "\n",
        "top9 = pd.merge(top9_df, lounge_df, left_on= 'lounge_index', right_on='라운지', how ='left')\n",
        "print(top9)\n",
        "\n",
        "output = top9[['건물', '라운지']].copy().to_records(index=False)\n",
        "print(output)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6.926393  5.8087544 6.5154033 6.30055   6.410085  6.9163394 6.2371817\n",
            " 5.8771296 5.787267  5.864695  6.003094  7.0662246 5.5169005 4.4126697\n",
            " 4.9704175 4.2053447 4.3767376 4.3252935 4.4497705 4.1954894 4.0345206\n",
            " 3.9116042 3.8154883 3.1527174 7.891381  8.153576  7.624625  6.464885\n",
            " 7.8311334 7.159326  4.0275617 4.199926  4.533246  4.360554  4.1686797\n",
            " 4.2628036 3.1502118 3.6647983 3.2585378 4.1191106 4.5642114 5.647385\n",
            " 4.882525  5.386312  3.845696  4.1843085 3.8311515 4.8887467 4.5325694\n",
            " 6.3571873 6.927006  6.754441  4.8096395 6.2450624 6.0353293 6.2622886\n",
            " 5.4684052 5.818083  5.552215  6.6462255 6.0463552 5.8456483 5.5090175\n",
            " 5.8612704 5.2118945 5.99673   6.745468  5.713326  5.7030454 5.738502\n",
            " 4.343372  4.2333226 6.63751   6.098305  5.8622847 6.45756   5.6270094\n",
            " 5.804439  6.7525916 6.870896  5.4741836 5.9141245 2.918114  4.3454037\n",
            " 4.4766636 4.5055537 4.443959  5.075812  5.434859  5.4968886 4.3145223\n",
            " 4.7029915 4.166806  4.851444  3.9981139 3.1879573 5.333201  6.552266\n",
            " 7.07409   7.143703  7.8610115 6.9436135 5.2452974 6.199948  4.327124\n",
            " 3.6621284 5.014441  4.0574284 5.036823  5.1668706 6.2209907 4.914362\n",
            " 5.1640925 4.871312  5.1331515 4.1989794 5.129061  5.727162  4.6633477\n",
            " 4.610221  5.8841343 4.298105  5.4131746 2.6702418 4.7580867 4.4929132\n",
            " 3.4093177 4.3100557 4.9673305 3.3082027 6.38179   6.157237  5.9520335\n",
            " 7.962016  7.8841853 7.665828  7.396288  6.885979  6.899218  4.494228\n",
            " 3.968971  3.0430968 3.3355825 4.1111727 4.621787  4.405937  3.823345\n",
            " 4.171797  4.913634  5.3876343 4.0196524 3.9619336 4.767375  4.0739217\n",
            " 5.592384  4.7036824 3.175025  2.5373707 2.324367  3.4482558 2.9876604\n",
            " 3.2161574 2.717519  2.575039  2.9439588 3.7745147 3.2690768 3.8008945\n",
            " 3.060661  4.1862726 3.4708028 2.4592533 4.217407  5.183435  5.1796794\n",
            " 4.524874  6.612951  6.4412627 5.6796327 7.798035  5.650871  6.6960506\n",
            " 6.192153  5.8956766 5.5333385 5.865581  5.4411464 3.2523236 4.282992\n",
            " 4.1811314 6.279067  4.8499875 5.855894  4.2357135 4.405291  3.8379493\n",
            " 4.5945063 4.999335  5.8250246 5.3170877 5.5311    6.179863  4.987282\n",
            " 5.6083713 3.7124867 4.498066  5.006182  4.0025    4.787204  3.6358457\n",
            " 3.5543098 6.3214126 6.755318  8.011426  4.0349154 5.020758  4.9715543\n",
            " 4.668468  3.4110959 3.6070395 3.2649052 3.2328682 2.7894719 3.2643402\n",
            " 1.6484782 3.314058  5.8071914 5.067595  5.8312244 3.600001  3.4128323\n",
            " 4.2030106 2.7386062 4.3741097 3.9150267 3.6699944 5.236569  5.258621\n",
            " 5.5415854]\n",
            "[224 158 171 157 163 123 162 232 222  82 164 160 141 168  36  23 156  95\n",
            " 161 221 187  38 223 220 166 129 225 142 126 218 230 159 170 210 229 219\n",
            " 209 105  37 235 204 165 167  22 146  46 195  44  21 234 151 140  94 207\n",
            " 150  30  20 214 107 153 143  39  92  34 147 189  45 169  19 115  31 231\n",
            "  15 172  71 193  35 188 121 127  90  17 104  70  83  33 233  16 194 145\n",
            "  13  86  18  84 125 139 205  85 175  48  32  40 196 119 144 118 217  91\n",
            " 155 124 152 208  52 191  93 113  42  47 148 111 128  14 216 202 197 206\n",
            " 106 215 108 227  87 116 114 112 109 174 173  64 236 102 237 199  96  43\n",
            " 149 122  88 186  56  80  89  62  12 200 184 238  58 154 203  76  41 180\n",
            " 178  68  67 117  69   8  77 226   1  57 198 228  61 192  63  74   9 185\n",
            "   7 120 183  81 132  65  10  54  60  73 131 201 182 103 110   6  53  55\n",
            " 190   3 211  49 130   4 177  75  27   2  97 176  72  59 181  66  78  51\n",
            " 212  79 137 138   5   0  50 101  11  98  99  29 136  26 135 179  28 100\n",
            " 134  24 133 213  25]\n",
            "[155 140 138  39  49  86   7  71  30  34 173 129 169  26   0  22   8  19\n",
            "  23  35  29 106 122 127  57 237 216 200  33  36 111  53 125  96  40 158\n",
            " 123 191 153 141 172 124 102  46  88  75 175 113 198  65  77  20 147 179\n",
            " 154 182 192 212 161 231 162 204 209  98 135 136  73   2  32  67  13  42\n",
            "  24  41  10   4   6  18  11  31   1   3  16 108 157  59 110  50  54 144\n",
            " 118  64  44  89 104  60  27  12  51  95 219 218 228 230 234 236 184 190\n",
            " 202  25 120  79  28  94 109   5 145  78 181 103 105 165 131  69 132 115\n",
            " 133 119 194 134 128  58 126  37  82 193 139 223 233 226 225 208 142  17\n",
            "  52 114  62 107  80 150 146 130  91  97  93  84   9 183 149 217 214 168\n",
            " 159 205 177 189 210  74  83 166 163 164 213 185 137 176 151 174 188 211\n",
            " 156 171 148 197 187 196 112 215 222 201  99 117  45  66  47 143 116 160\n",
            " 101  61  21  38  14  76  63  85 100  70  55 227 232 206 229 238 235  15\n",
            "  43  48  56  68  92  81  87  72 121  90 152 224 186 178 167 180 195 220\n",
            " 203 199 207 170 221]\n",
            "[155 140 138  39  49  86   7  71  30]\n",
            "   lounge_index\n",
            "0           155\n",
            "1           140\n",
            "2           138\n",
            "3            39\n",
            "4            49\n",
            "5            86\n",
            "6             7\n",
            "7            71\n",
            "8            30\n",
            "   lounge_index  라운지  책상 높이  테이블 수  의자 수  ...  정수기  화장실       혼잡도     거리  건물\n",
            "0           155  155      0      7    21  ...    0    1  0.209458  135.8  85\n",
            "1           140  140      0     11    33  ...    0    1  0.288587  256.9  88\n",
            "2           138  138      0      5    25  ...    0    1  0.609569  113.0  20\n",
            "3            39   39      1     11    11  ...    1    0  0.002552   70.3  44\n",
            "4            49   49      1      2     4  ...    0    1  0.582855  166.8  66\n",
            "5            86   86      1      5    25  ...    0    1  0.062296   65.9  65\n",
            "6             7    7      1     10    20  ...    1    1  0.351093  169.0  28\n",
            "7            71   71      1      3     3  ...    1    1  0.270524  180.6  33\n",
            "8            30   30      1      7    35  ...    0    0  0.186370  121.1  61\n",
            "\n",
            "[9 rows x 14 columns]\n",
            "[(85, 155) (88, 140) (20, 138) (44,  39) (66,  49) (65,  86) (28,   7)\n",
            " (33,  71) (61,  30)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n    print(out.size())\\n    out= out.reshape(1,82)\\n    print(out.size())\\n    out = nn.Softmax(dim=1)(out)\\n    print(out)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "5M2X6f7QoT1-",
        "outputId": "3f9aeb41-780e-45c7-d30f-c58fcc26b06c"
      },
      "source": [
        "# 학습 과정 중 저장해둔 모든 loss 그래프화\n",
        "writer.close()\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir runs "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Launching TensorBoard..."
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}