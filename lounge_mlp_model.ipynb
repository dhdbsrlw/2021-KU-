{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lounge_mlp_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eZnlUWAGOlL",
        "outputId": "2aa9f221-3660-48ac-968c-c6ce44900582"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "tiKhXZRZGXCt",
        "outputId": "924665f3-3b7a-452f-c14c-a5b7347dddcb"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import sqlite3\n",
        "\n",
        "def_path = '/content/drive/Shareddrives/데이터톤/보고서 작성 시 사용할 최종 파일/데이터 및 전처리/'\n",
        "\n",
        "#\t라운지\t위치(층)\t책상 높이\t테이블 수\t의자 수\t냉난방장치\t콘센트 수\t창문\t컴퓨터\t정수기\t화장실\t혼잡도  건물\n",
        "raw_data_lounge = pd.read_csv(def_path+'라운지+혼잡도/라운지 데이터 최종.csv',encoding='euc-kr')\n",
        "raw_data_lounge['건물'] = raw_data_lounge['건물'].replace({' ':''}, regex=True)\n",
        "\n",
        "# 랜드마크 간의 거리 구하기\n",
        "distance_buildings = pd.read_csv(def_path+'건물별 이동시간 최종.csv',encoding='utf-8')\n",
        "\n",
        "encoding_df = pd.read_csv(def_path+'건물 인코딩.csv')\n",
        "\n",
        "def df_completion(user):\n",
        "    user_building = user[0]\n",
        "    distance = distance_buildings[['building', user_building]].copy()\n",
        "    distance.rename(columns = {user_building: '거리'}, inplace = True)\n",
        "\n",
        "    #라운지\t위치(층)\t책상 높이\t테이블 수\t의자 수\t냉난방장치\t콘센트 수\t창문\t컴퓨터\t정수기\t화장실\t혼잡도\t건물\t***거리\n",
        "    lounge_with_distance = pd.merge(raw_data_lounge, distance, left_on= '건물', right_on='building', how ='left' ).drop(columns=['building'])\n",
        "\n",
        "    day = str(pd.to_datetime(user[1].split('T')[0]).dayofweek)\n",
        "    congestion_path = def_path+'라운지+혼잡도/혼잡도_'\n",
        "    user_c = pd.read_csv(congestion_path+'월.csv')\n",
        "\n",
        "    #find day\n",
        "    if day==1:\n",
        "        user_c =  pd.read_csv(congestion_path+'화.csv')\n",
        "    elif day==2:\n",
        "        user_c = pd.read_csv(congestion_path+'수.csv')\n",
        "    elif day==3:\n",
        "        user_c = pd.read_csv(congestion_path+'목.csv')\n",
        "    elif day==4:\n",
        "        user_c = pd.read_csv(congestion_path+'금.csv')\n",
        "\n",
        "    range = pd.date_range(\"09:00\", \"23:30\", freq=\"30min\").strftime('%H:%M:%S')\n",
        "    dt = pd.to_datetime(user[1]).round('30min')\n",
        "    user_c_r = range.get_loc(str(dt).split(' ')[1].split('+')[0])\n",
        "\n",
        "    #라운지\t위치(층)\t책상 높이\t테이블 수\t의자 수\t냉난방장치\t콘센트 수\t창문\t컴퓨터\t정수기\t화장실\t***혼잡도\t건물    거리\n",
        "    lounge_with_congestion = lounge_with_distance\n",
        "    lounge_with_congestion['혼잡도']=lounge_with_congestion.apply(lambda row: user_c[row.건물][user_c_r], axis=1)\n",
        "\n",
        "    # classroom encoding (건물이름 --> 숫자)\n",
        "    final_lounge = pd.merge(lounge_with_congestion, encoding_df, left_on= '건물', right_on='building', how ='left')\n",
        "    final_lounge = final_lounge.drop(['building','위치(층)'], axis =1)\n",
        "    final_lounge = final_lounge.rename({'건물':'building_name','라운지':'lounge_name','encoding':'건물', 'lounge_index':'라운지'},axis=1)\n",
        "    print(final_lounge)\n",
        "    return final_lounge\n",
        "\n",
        "# 모델 --> 없으면 모델을 불러올 수가 없음\n",
        "class NNCollabFiltering(nn.Module):\n",
        "    def __init__(self, emb_size=10, n_hidden=100):\n",
        "        super(NNCollabFiltering, self).__init__()\n",
        "        self.emb_size = emb_size\n",
        "        self.user_emb = nn.Embedding(100, emb_size)\n",
        "        self.item_emb = nn.Embedding(600, emb_size)\n",
        "        self.lin1 = nn.Linear(1000, n_hidden)\n",
        "        self.lin2 = nn.Linear(n_hidden, 1)\n",
        "        self.drop1 = nn.Dropout(0.1)\n",
        "        \n",
        "    def forward(self, u, v):\n",
        "        U = self.user_emb(u)\n",
        "        U = torch.reshape(U, (239, 6 * self.emb_size))\n",
        "        V = self.item_emb(v)\n",
        "        V = torch.reshape(V, (239, 12 * self.emb_size))\n",
        "        x = F.relu(torch.cat([U, V], dim=1))\n",
        "        x = self.drop1(x)\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = self.lin2(x)\n",
        "        x = torch.flatten(x)\n",
        "        return x\n",
        "\n",
        "def fetch_model(theme):\n",
        "    # 모델 불러오기\n",
        "    PATH = def_path+'라운지+혼잡도/model_'\n",
        "\n",
        "    if theme in range (1,4):\n",
        "        PATH = PATH + str(theme) + '/'\n",
        "    else:\n",
        "        PATH = PATH + '0/'\n",
        "\n",
        "    model = torch.load(PATH + 'model.pt')  \n",
        "    model.load_state_dict(torch.load(PATH + 'model_state_dict.pt'))  \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay= 1e-6)\n",
        "\n",
        "    checkpoint = torch.load(PATH + 'all.tar')  \n",
        "    model.load_state_dict(checkpoint['model'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# softmax 함수 (약간의 추천 랜덤성 부여를 위해 사용)\n",
        "def softmax(a) :\n",
        "    exp_a = np.exp(a)\n",
        "    sum_exp_a = np.sum(exp_a)\n",
        "    y = exp_a / sum_exp_a\n",
        "    \n",
        "    return y\n",
        "\n",
        "\n",
        "###############       9개 라운지 추천해주는 모델      ########################\n",
        "def lounge_Top9(theme, location, time, num_user, table, plug, computer, facility):\n",
        "  \n",
        "  # 인원 수, 시간 정보 사용 안함 \n",
        "  new_user = [location, time, num_user, table, plug, computer, facility]\n",
        "\n",
        "  lounge_df_norm = df_completion(new_user)\n",
        "  lounge_df = lounge_df_norm.drop(['building_name','lounge_name'], axis =1)\n",
        "\n",
        "  building_row = encoding_df.loc[encoding_df['building'] == location]\n",
        "  encoding = building_row.iloc[0]['encoding']\n",
        "  new_user[0] = encoding\n",
        "  new_user.pop(1)\n",
        "\n",
        "  \n",
        "  model = fetch_model(theme)\n",
        "  # 학습된 모델을 이용해 각 라운지에 대한 사용자 점수 계산\n",
        "  with torch.no_grad():\n",
        "    user_scale = np.array(new_user*239).reshape((239,6))\n",
        "    user_input = torch.LongTensor(user_scale)\n",
        "    l = lounge_df.to_numpy()\n",
        "    lounge_input = torch.LongTensor(l[:,1:])\n",
        "    out = model(user_input, lounge_input).numpy()\n",
        "    sort_out = np.argsort(out)[::-1]\n",
        "    sort_out_score = out[sort_out]\n",
        "  \n",
        "  # Softmax 추천 알고리즘\n",
        "  top9_index = np.random.choice(sort_out, 9, p=softmax(sort_out_score), replace=False)\n",
        "  top9_df = pd.DataFrame(top9_index, columns =['라운지'])\n",
        "\n",
        "  top9 = pd.merge(top9_df, lounge_df_norm, on= '라운지', how ='left')\n",
        "  output = top9[['building_name', 'lounge_name']].copy().to_records(index=False)\n",
        "    \n",
        "  return output \n",
        "####################################################################################\n",
        "\n",
        "\n",
        "result = lounge_Top9(1, '국제관', '2021-08-09T15:00:00+09:00',5,5,2,1,0)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-21c49235b415>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#       라운지     위치(층)   책상 높이   테이블 수   의자 수    냉난방장치   콘센트 수   창문      컴퓨터     정수기     화장실     혼잡도  건물\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mraw_data_lounge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdef_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'라운지+혼잡도/라운지 데이터 최종.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'euc-kr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mraw_data_lounge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'건물'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_data_lounge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'건물'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1991\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m                 \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/Shareddrives/데이터톤/보고서 작성 시 사용할 최종 파일/데이터 및 전처리/라운지+혼잡도/라운지 데이터 최종.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMv3qtfcrdZ0"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-gMaStPrO14"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLkUzp0qrPvR"
      },
      "source": [
        ""
      ]
    }
  ]
}